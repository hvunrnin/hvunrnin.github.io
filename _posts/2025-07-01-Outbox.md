---
title: "Outbox 패턴 도입"
author: "hvunrnin"
date: 2025-07-01 10:00:00 
categories: [BackEnd, Outbox, MongoDB, Transaction]
tags: [MongoDB, Springboot]
math: true
toc: true
pin: true
---

# DB 저장, Kafka Publish 트랜잭션을 위한 Outbox 패턴 적용

## 기존 시스템 구조

아래와 같은 구조로 기존 채팅 메시지의 흐름을 비동기 메시지 기반 아키텍처로 처리했다.

<p align="center">
  <img src="assets/img/OUTBOX/chat_archi.png"  alt="채팅 시스템 아키텍처 흐름도" width="800"/>
</p>


### ⚠️ 문제점

이 구조로 하면 다음과 같은 **트랜잭션 불일치 문제**로 인해 메시지 누락!!이 존재했음:

- Kafka에 메시지를 먼저 보내고 MongoDB에 나중에 저장 → 저장 실패 시 메시지 유실
- Kafka Consumer(Spring B)가 죽었을 경우, 메시지를 읽지 못하고 저장도 못함
- MongoDB와 Kafka가 분리되어 있어 장애 복구나 메시지 추적이 어렵고 비결정적


그래서 이 문제를 해결하기 위해, Outbox 패턴을 적용하여 메시지를 먼저 DB에 저장한 후 Kafka로 전송하는 구조를 추가하게 되었다.


## Outbox 패턴이란
Outbox 패턴은 **비동기 메시징 시스템에서 데이터 유실을 방지하기 위한 설계 패턴**이다.

내 상황에선 사용자의 채팅 메시지를 Kafka에 발행하고, 동시에 DB에도 저장해야 하는 경우에 딱 필요했다. 이 둘의 트랜잭션이 분리되어 있는 상태여서 아래와 같은 누락 이슈가 발생한다.

- Kafka 발행은 성공했지만 DB 저장 실패 → 메시지 유실
- DB에는 저장됐지만 Kafka 발행 실패 → 사용자에게 미전달

이런 **트랜잭션 불일치 문제**를 해결하기 위한 대표적인 방법이 **Outbox 패턴**이다.

<br>

### Outbox 처리 방식 비교: Polling vs Change Stream

이 Outbox를 구현하기 위한 대표적인 2가지 방식이 있는데,

- **Polling**: 일정 주기로 DB를 조회해서 발행할 메시지가 있으면 Kafka로 보내는 방식
- **Change Stream**: MongoDB의 실시간 이벤트 스트리밍 기능을 이용해 메시지 삽입을 즉시 감지하는 방식

<br>

| 항목 | Polling 방식 | Change Stream 방식 (적용한 방식) |
|------|--------------|-----------------------------------|
| **Outbox INSERT** | 동일 (DB에 PENDING 저장) | 동일 (DB에 PENDING 저장) |
| **Kafka 발행** | Poller가 일정 주기로 쿼리 (예: 5초마다) | MongoDB가 실시간으로 이벤트 푸시 |
| **상태 관리** | Poller가 메시지 발행 후 상태를 SENT로 업데이트 | Change Stream Listener가 발행 후 바로 SENT로 업데이트 |
| **실시간성** | 낮음 (딜레이 존재) | 높음 (거의 실시간) |
| **구현 난이도** | 비교적 쉬움 | 초기 셋업은 복잡하지만 구조는 간결 |
| **추가 Infra 필요** | 스케줄러 또는 배치 Poller | 없음 (Spring Data MongoDB 사용) |
| **성능 부하** | 주기적 쿼리로 DB 부하 가능성 | 이벤트 기반으로 상대적으로 안정적 |


<br>

### 왜 Change Stream 기반으로 선택했는지??

채팅 서비스 특성상, **메시지 지연을 높은 우선순위로 고려해야되기 때문에** Polling 방식보다는 실시간성이 뛰어난 **Change Stream 기반 Outbox** 구조가 훨씬 유리하다고 생각했음.

- 실시간 채팅이라는 서비스 특성상 레이턴시가 매우 중요
- Polling 주기 없이 밀리초 단위 반응 가능, Polling Job이나 Scheduler 없이 처리 흐름을 단순화할 수 있음
- 별도 infra 없이 Spring MongoDB만으로도 충분
- Change Stream은 MongoDB의 native 기능이라 외부 인프라 없이도 고성능 이벤트 기반 처리 가능
- 메시지 상태 전이(PENDING → SENT)를 처리 흐름 안에서 자동화 가능

<br>
<br>

## Outbox 패턴 도입으로 아키텍처 재설계

### 설계 방식
이번 프로젝트에서는 Outbox 테이블 대신 **MongoDB 컬렉션(chat_messages_ind)**를 사용했고,  
메시지는 상태값(`PENDING → SENT`)을 관리하며 다음 흐름으로 처리되게 했다.

**장점**
- Kafka와 DB 간의 데이터 정합성 보장
- Kafka 발행 실패 시 재시도 가능
- 메시지 상태값 관리로 추적성 향상
- 장애 발생 시 재처리 로직 단순화


설계방식을 정리하면 아래와 같다.
```plaintext
1. Kafka Consumer(chat-message) → MongoDB(status: PENDING)
2. MongoDB Change Stream 감지 → Kafka(chat-message-sent) 발행
3. 상태 PENDING → SENT로 업데이트
4. Kafka Consumer(chat-message-sent) → WebSocket 전달
```

<br>

### 수정된 핵심 코드

#### - MongoDB Document 구조 수정 → `status` 필드 추가

Kafka 발행 전후의 메시지 처리 상태를 추적하기 위해  
MongoDB Document(chat_messages_ind)에 `status` 필드를 추가부터 했다.
```java
public class ChatMessageDocument {

    @Id
    private String id;

    private String roomId;
    private String sender;
    private Instant timestamp;
    private String message;

    private String messageType; 
    private String status; // "PENDING", "SENT"
}
```

#### - Kafka 메시지를 수신하고 상태를 `PENDING`으로 저장

처음에 메시지가 들어오면 status를 바로 pending상태로 저장시켰다.

```java
    public void saveMessage(String roomId, String sender, String content, String messageType, Instant timestamp) {

        ChatMessageDocument document = ChatMessageDocument.builder()
                .roomId(roomId)
                .sender(sender)
                .message(content)
                .timestamp(timestamp)
                .messageType(messageType)
                .status("PENDING")
                .build();

        chatMessageMongoRepository.save(document);
    }
```


#### - MongoDB Change Stream으로 `PENDING` 상태 감지 → Kafka 발행 → 상태를 `SENT`로 변경

```java
public class KafkaChatConsumer {

    private final ChatMessageMongoService chatMessageMongoService;
    private final KafkaSendMsgProducer kafkaSendMsgProducer;

    @KafkaListener(topics = "chat-message", groupId = "${spring.kafka.consumer.group-id}",
            containerFactory = "kafkaListenerContainerFactory")
    public void consume(ChatKafkaMessage message) {
        log.info("Kafka 메시지 수신: {}", message);

        // 1. MongoDB 저장
        chatMessageMongoService.saveMessage(
                message.getRoomId(),
                message.getSender(),
                message.getMessage(),
                message.getMessageType(),
                message.getTimestamp() != null ? message.getTimestamp() : Instant.now()
        );

        // 2. 저장 완료 후 다시 Kafka로 전송
//        kafkaSendMsgProducer.send(message);
    }
}
```
기존에는 위처럼 mongodb에 저장하자마자 kafka로 전송을 KafkaChatConsumer에서 바로 했는데 이걸

```java
public class ChatMessageChangeStreamListener {

    private final MongoTemplate mongoTemplate;
    private final ChatMessageMongoRepository chatMessageMongoRepository;
    private final KafkaSendMsgProducer kafkaSendMsgProducer;
    private final ObjectMapper objectMapper;

    @EventListener(ApplicationReadyEvent.class)
    public void listenChangeStream() {

        mongoTemplate.getCollection("chat_messages_ind")
                .watch()
                .forEach((ChangeStreamDocument<Document> change) -> {
                    Document fullDoc = change.getFullDocument();
                    if (fullDoc == null) return;

                    String id = fullDoc.getObjectId("_id").toHexString();

                    try {
                        chatMessageMongoRepository.findById(id).ifPresent(doc -> {
                            if (!"PENDING".equals(doc.getStatus())) {
                                return; // 이미 처리됨
                            }

                            ChatKafkaMessage msg = ChatKafkaMessage.builder()
                                    .roomId(doc.getRoomId())
                                    .sender(doc.getSender())
                                    .message(doc.getMessage())
                                    .timestamp(doc.getTimestamp())
                                    .messageType(doc.getMessageType())
                                    .build();

                            // Kafka 퍼블리시
                            kafkaSendMsgProducer.send(msg);

                            // 상태 SENT로 변경
                            doc.setStatus("SENT");
                            chatMessageMongoRepository.save(doc);
                        });

                    } catch (Exception e) {
                        log.error("Change Stream 발행 실패: {}", e.getMessage(), e);
                    }
                });
    }

}
```

이걸 MongoDB에 PENDING 메시지가 저장되면, Change Stream이 이를 실시간 감지 -> 
Kafka로 메시지를 발행한 후, 해당 메시지의 status를 "SENT"로 변경하는 형태로 바꿔주었다.

결과적으로 위에서 설계한 그대로 고쳤다!!

<br>
<br>

## MongoDB에서 ChangeStream을 사용하기 위해서..
위와 같이 코드를 바꾸고 서버에 변경된 걸 올렸는데 예상과 달리 안 돌아감..

```vbnet
com.mongodb.MongoCommandException: 
Command failed with error 40573 (Location40573): 
'The $changeStream stage is only supported on replica sets'
```
이러너 눈물 나는 오류가 뜸.
확인해보니 MongoDB의 $changeStream 은 Standalone 모드에선 지원 안 됨! → Replica Set 모드에서만 지원됨이라는 상황..

알고보니 **MongoDB의 Change Stream 기능은 반드시 Replica Set 환경에서만 동작**하는 거였다. 단일 노드로 실행되는 Standalone 모드에서는 `watch()` API가 `IllegalOperation` 예외를 발생시켜 계속 오류가 뜨는 것이었다.

그래서
 ```yaml
version: '3'
services:
  mongodb:
    image: mongo:6.0
    container_name: mongodb
    ports:
      - 
    volumes:
      - ./db/mongodb/data:/data/db
      - ./db/mongodb/init:/docker-entrypoint-initdb.d
    command: >
      mongod --replSet rs0 --bind_ip_all
```

이런 식으로 도커파일에서 mongodb 설정을 수정해줬다.

이러면 정말 끝~!