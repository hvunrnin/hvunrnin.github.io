---
title: "Chatting + Kafka"
author: "hvunrnin"
date: 2025-05-29 10:00:00 
categories: [BackEnd, SpringBoot, Kafka, WebSocket]
tags: [SpringBoot, Chatting]
math: true
toc: true
pin: true
---

# 💬 Kafka를 활용한 채팅 시스템 설계

---

## 1. Kafka 도입하기

채팅 시스템을 만들면서 가장 먼저 고민한 건  
**"실시간 메시지를 어떻게 안정적으로 전달할 것인가?"**였다.

기존의 **WebSocket 기반 단일 서버 구조**는 소규모 서비스에선 충분했지만,  
**다중 서버로 확장**을 고려하면 다음과 같은 **한계**가 존재했다:

- 서버가 수평 확장될수록 WebSocket 연결을 **분산 처리하기 어려움**
- 특정 서버가 다운되면 해당 서버에 연결된 **사용자 메시지 유실 가능성**
- 메시지를 DB에 저장하거나 알림을 전송하는 등의 처리를 **동기적으로 진행하면 응답 지연 발생**

---

이런 문제를 해결하기 위해 **메시지 브로커**를 도입했고,  
그중에서도 **Kafka**를 선택한 이유는 다음과 같다:

> ✅ **높은 처리량과 내결함성**  
> ✅ **Consumer Group 기반 분산 처리 지원**  
> ✅ **다수의 Consumer가 독립적으로 메시지를 소비할 수 있음**

Kafka는 다양한 컴포넌트 (WebSocket, DB 저장, 알림 등) 간의  
**비동기 처리 구성**에 매우 용이하다.

처음 Kafka를 붙일 때는 **단순한 구조**로 시작했다.

---

## 2. 초기 구조 설계

Kafka를 처음 붙였을 때는  
**한 개의 Spring Boot 애플리케이션이 Producer와 Consumer 역할을 모두 수행**하는 구조였다.

메시지 흐름은 다음과 같았다:

1. WebSocket을 통해 메시지를 수신한 서버가 Kafka의 `send_msg` Topic에 메시지를 전송 (**Producer**)
2. 같은 서버 내 **Consumer**가 `send_msg`를 수신하고 **MongoDB에 저장**
3. 이후 저장된 메시지를 Kafka의 `receive_msg` Topic으로 전송 (**Producer**)
4. 다른 Consumer가 이 메시지를 받아 **WebSocket으로 사용자에게 전달**

<br>

<img src="assets/img/CHATTING/flow1.png" alt="flow 이미지1" style="width: 90%;">

---

이 구조는 **개발 초기엔 단순하고 작동도 잘 됐지만**,  
**다중 서버**로 확장하면서 문제가 발생할 수 있었다:

- Kafka의 **Consumer Group** 특성상, 같은 Group ID를 가진 Consumer는 **동일한 메시지를 한 번만 소비**
- 즉, WebSocket 연결 서버가 여러 개일 경우, **특정 서버에만 메시지가 전달**되고 **나머지는 누락**

이런 특성을 미처 고려하지 못했던 점이 문제였다.  
Kafka의 **Consumer Group 동작 방식**에 맞게 **구조를 재설계**할 필요가 생겼다.

---

## ⚠️ 3. 문제 발생: Kafka Consumer Group 동작 이슈 및 메시지 누락

당시 구조는 다음과 같았다:

- 모든 WebSocket 서버가 Kafka의 `receive_msg` Topic을 **구독**
- **모든 서버가 동일한 `groupId`**를 사용해 메시지를 소비

이 경우 발생하는 문제:

> ❗ Kafka에서는 **같은 Topic + 같은 Group ID**를 사용하는 Consumer Group에선  
> **각 메시지를 단 하나의 Consumer**에게만 전달함

따라서...

- 특정 서버에 연결된 사용자만 메시지를 수신  
- **나머지 서버에 연결된 사용자들은 메시지를 못 받음**  
- 이는 실시간 채팅 시스템에선 **치명적인 메시지 누락 버그**로 이어짐

Kafka의 Group ID 개념을 정확히 이해하지 못했던 결과였다.  
**구조 및 메시지 소비 방식을 근본적으로 재설계**할 필요가 있었다.

---

## 4. 해결 방향: 구조 분리 및 Group ID 설계 변경

Kafka의 동작 원리를 고려하여 전체 구조를 **역할별로 분리**했다.  
아래 그림과 같이 구조를 **다시 설계**했다:

<br>

<img src="assets/img/CHATTING/flow2.png" alt="flow 이미지2" style="width: 90%;">

---

### ✅ `send_msg` Consumer → **MongoDB 저장**
- Kafka의 `send_msg` Topic에서 메시지를 수신
- 메시지를 **DB에 한 번만 저장**해야 하므로
- 모든 인스턴스가 **같은 Group ID**를 사용해 **메시지를 분산 처리**

---

### ✅ `receive_msg` Consumer → **WebSocket 사용자 전송**
- Kafka의 `receive_msg` Topic에서 메시지를 수신
- WebSocket 서버 **각각이 동일한 메시지를 수신**해야 하므로
- **각 서버마다 고유한 Group ID**를 사용

---

### 🎯 결과

> - **MongoDB에는 중복 없이 정확히 한 번 저장**  
> - **모든 사용자에게 메시지가 누락 없이 브로드캐스트**

Kafka의 구조적 특성과 Group ID 설계를 바르게 이해한 덕분에  
**안정적인 채팅 시스템**으로 개선 완료!

---
